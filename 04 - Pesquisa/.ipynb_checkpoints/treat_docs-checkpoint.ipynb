{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat data\n",
    "\n",
    "In order to get a better model, we will restrict our data to:\n",
    "- only political news\n",
    "- from 2017\n",
    "\n",
    "This script filters this data from all the documents in the dataset and pre-process the text for the topics-over-time discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>errors</th>\n",
       "      <th>pausatility</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words in upper case</th>\n",
       "      <th>average sentence length</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>katia abreu diz vai colocar expulsao moldura, ...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.23080</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2017-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>10.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>dr. ray peita bolsonaro, chama-o conservador f...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.14290</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>100.txt</td>\n",
       "      <td>afolhabrasil.com.br</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>reinaldo azevedo desmascarado policia federal....</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.18750</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>1000.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>relatorio assustador bndes mostra dinheiro pub...</td>\n",
       "      <td>639.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.88000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2017-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>1001.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>radialista americano fala sobre pt: \"eles vend...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.84211</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      file                   link  category  emotiveness    errors  \\\n",
       "0  fake     1.txt  ceticismopolitico.com  politica     0.263158  0.000000   \n",
       "1  fake    10.txt  ceticismopolitico.com  politica     0.241667  0.007874   \n",
       "2  fake   100.txt    afolhabrasil.com.br  politica     0.127820  0.003636   \n",
       "3  fake  1000.txt     diariodobrasil.org  politica     0.229008  0.001748   \n",
       "4  fake  1001.txt     diariodobrasil.org  politica     0.269231  0.000000   \n",
       "\n",
       "   pausatility                                               text  tokens  \\\n",
       "0     2.000000  katia abreu diz vai colocar expulsao moldura, ...   211.0   \n",
       "1     2.500000  dr. ray peita bolsonaro, chama-o conservador f...   289.0   \n",
       "2     1.812500  reinaldo azevedo desmascarado policia federal....   304.0   \n",
       "3     2.680000  relatorio assustador bndes mostra dinheiro pub...   639.0   \n",
       "4     0.894737  radialista americano fala sobre pt: \"eles vend...   128.0   \n",
       "\n",
       "   words in upper case  average sentence length  nouns  verbs  adverbs  \\\n",
       "0                  6.0                 14.23080   46.0   30.0     13.0   \n",
       "1                  0.0                 18.14290   64.0   56.0     18.0   \n",
       "2                  0.0                 17.18750   88.0   45.0      8.0   \n",
       "3                 14.0                 22.88000  175.0   87.0     21.0   \n",
       "4                  1.0                  5.84211   31.0   21.0      8.0   \n",
       "\n",
       "   adjectives  pronouns        date  \n",
       "0         7.0      26.0  2017-11-30  \n",
       "1        11.0      20.0  2017-11-24  \n",
       "2         9.0      18.0  2017-05-23  \n",
       "3        39.0      34.0  2017-07-24  \n",
       "4         6.0      12.0  2017-07-25  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_csv = \"../02 - Analise exploratoria/all_together.csv\"\n",
    "df = pd.read_csv(file_csv)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All categories: {'sociedade_cotidiano', 'ciencia_tecnologia', 'politica', 'economia', 'tv_celebridades', 'religiao'}\n",
      "Ratio: 4180/7200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>errors</th>\n",
       "      <th>pausatility</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words in upper case</th>\n",
       "      <th>average sentence length</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>katia abreu diz vai colocar expulsao moldura, ...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.23080</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2017-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>10.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>dr. ray peita bolsonaro, chama-o conservador f...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.14290</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>100.txt</td>\n",
       "      <td>afolhabrasil.com.br</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>reinaldo azevedo desmascarado policia federal....</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.18750</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>1000.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>relatorio assustador bndes mostra dinheiro pub...</td>\n",
       "      <td>639.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.88000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2017-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>1001.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>radialista americano fala sobre pt: \"eles vend...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.84211</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      file                   link  category  emotiveness    errors  \\\n",
       "0  fake     1.txt  ceticismopolitico.com  politica     0.263158  0.000000   \n",
       "1  fake    10.txt  ceticismopolitico.com  politica     0.241667  0.007874   \n",
       "2  fake   100.txt    afolhabrasil.com.br  politica     0.127820  0.003636   \n",
       "3  fake  1000.txt     diariodobrasil.org  politica     0.229008  0.001748   \n",
       "4  fake  1001.txt     diariodobrasil.org  politica     0.269231  0.000000   \n",
       "\n",
       "   pausatility                                               text  tokens  \\\n",
       "0     2.000000  katia abreu diz vai colocar expulsao moldura, ...   211.0   \n",
       "1     2.500000  dr. ray peita bolsonaro, chama-o conservador f...   289.0   \n",
       "2     1.812500  reinaldo azevedo desmascarado policia federal....   304.0   \n",
       "3     2.680000  relatorio assustador bndes mostra dinheiro pub...   639.0   \n",
       "4     0.894737  radialista americano fala sobre pt: \"eles vend...   128.0   \n",
       "\n",
       "   words in upper case  average sentence length  nouns  verbs  adverbs  \\\n",
       "0                  6.0                 14.23080   46.0   30.0     13.0   \n",
       "1                  0.0                 18.14290   64.0   56.0     18.0   \n",
       "2                  0.0                 17.18750   88.0   45.0      8.0   \n",
       "3                 14.0                 22.88000  175.0   87.0     21.0   \n",
       "4                  1.0                  5.84211   31.0   21.0      8.0   \n",
       "\n",
       "   adjectives  pronouns        date  \n",
       "0         7.0      26.0  2017-11-30  \n",
       "1        11.0      20.0  2017-11-24  \n",
       "2         9.0      18.0  2017-05-23  \n",
       "3        39.0      34.0  2017-07-24  \n",
       "4         6.0      12.0  2017-07-25  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All categories:\", set(df[\"category\"]))\n",
    "\n",
    "df_politica = df.loc[df[\"category\"] == \"politica\"].copy()\n",
    "print(f\"Ratio: {len(df_politica)}/{len(df)}\")\n",
    "\n",
    "df_politica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: 1718/7200 (0.24)\n",
      "True: 936\n",
      "Fake: 782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>errors</th>\n",
       "      <th>pausatility</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words in upper case</th>\n",
       "      <th>average sentence length</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>katia abreu diz vai colocar expulsao moldura, ...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.23080</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2017-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>10.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>dr. ray peita bolsonaro, chama-o conservador f...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.14290</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>100.txt</td>\n",
       "      <td>afolhabrasil.com.br</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>reinaldo azevedo desmascarado policia federal....</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.18750</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>1000.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>relatorio assustador bndes mostra dinheiro pub...</td>\n",
       "      <td>639.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.88000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2017-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>1001.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>radialista americano fala sobre pt: \"eles vend...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.84211</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      file                   link  category  emotiveness    errors  \\\n",
       "0  fake     1.txt  ceticismopolitico.com  politica     0.263158  0.000000   \n",
       "1  fake    10.txt  ceticismopolitico.com  politica     0.241667  0.007874   \n",
       "2  fake   100.txt    afolhabrasil.com.br  politica     0.127820  0.003636   \n",
       "3  fake  1000.txt     diariodobrasil.org  politica     0.229008  0.001748   \n",
       "4  fake  1001.txt     diariodobrasil.org  politica     0.269231  0.000000   \n",
       "\n",
       "   pausatility                                               text  tokens  \\\n",
       "0     2.000000  katia abreu diz vai colocar expulsao moldura, ...   211.0   \n",
       "1     2.500000  dr. ray peita bolsonaro, chama-o conservador f...   289.0   \n",
       "2     1.812500  reinaldo azevedo desmascarado policia federal....   304.0   \n",
       "3     2.680000  relatorio assustador bndes mostra dinheiro pub...   639.0   \n",
       "4     0.894737  radialista americano fala sobre pt: \"eles vend...   128.0   \n",
       "\n",
       "   words in upper case  average sentence length  nouns  verbs  adverbs  \\\n",
       "0                  6.0                 14.23080   46.0   30.0     13.0   \n",
       "1                  0.0                 18.14290   64.0   56.0     18.0   \n",
       "2                  0.0                 17.18750   88.0   45.0      8.0   \n",
       "3                 14.0                 22.88000  175.0   87.0     21.0   \n",
       "4                  1.0                  5.84211   31.0   21.0      8.0   \n",
       "\n",
       "   adjectives  pronouns        date  \n",
       "0         7.0      26.0  2017-11-30  \n",
       "1        11.0      20.0  2017-11-24  \n",
       "2         9.0      18.0  2017-05-23  \n",
       "3        39.0      34.0  2017-07-24  \n",
       "4         6.0      12.0  2017-07-25  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use = df_politica.dropna(subset=[\"date\"], how=\"all\").copy()\n",
    "# Easier to do as a string\n",
    "df_2017 = df_use.loc[df[\"date\"].str.startswith(\"2017\", na=False)].copy()\n",
    "\n",
    "print(f\"Ratio: {len(df_2017)}/{len(df)} ({len(df_2017)/len(df):.2f})\")\n",
    "print(f\"True: {len(df_2017.loc[df['label'] == 'true'])}\")\n",
    "print(f\"Fake: {len(df_2017.loc[df['label'] == 'fake'])}\")\n",
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process text\n",
    "\n",
    "Before running topics discovery, we must pre-process the documents texts.\n",
    "To do that, we apply the same process done for LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import spacy\n",
    "import stopwordsiso\n",
    "\n",
    "df_filtered = df_2017.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tokenize and Clean-up using gensim’s simple_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['katia',\n",
       " 'abreu',\n",
       " 'diz',\n",
       " 'vai',\n",
       " 'colocar',\n",
       " 'expulsao',\n",
       " 'moldura',\n",
       " 'reclamar',\n",
       " 'senadora',\n",
       " 'katia',\n",
       " 'abreu',\n",
       " 'sem',\n",
       " 'partido',\n",
       " 'to',\n",
       " 'disse',\n",
       " 'expulsao',\n",
       " 'pmdb',\n",
       " 'resultado',\n",
       " 'acao',\n",
       " 'cupula',\n",
       " 'atual',\n",
       " 'legenda',\n",
       " 'que',\n",
       " 'segundo',\n",
       " 'ela',\n",
       " 'oportunista',\n",
       " 'amanha',\n",
       " 'vou',\n",
       " 'botar',\n",
       " 'moldura',\n",
       " 'dourada',\n",
       " 'expulsao',\n",
       " 'porque',\n",
       " 'maos',\n",
       " 'onde',\n",
       " 'veio',\n",
       " 'atestado',\n",
       " 'boa',\n",
       " 'conduta',\n",
       " 'curriculo',\n",
       " 'essas',\n",
       " 'pessoas',\n",
       " 'expulsaram',\n",
       " 'servem',\n",
       " 'pais',\n",
       " 'eles',\n",
       " 'servem',\n",
       " 'pais',\n",
       " 'beneficios',\n",
       " 'proprios',\n",
       " 'disse',\n",
       " 'katia',\n",
       " 'abreu',\n",
       " 'ue',\n",
       " 'expulsao',\n",
       " 'algo',\n",
       " 'tao',\n",
       " 'bom',\n",
       " 'curriculo',\n",
       " 'tanta',\n",
       " 'choradeira',\n",
       " 'katia',\n",
       " 'sabemos',\n",
       " 'motivo',\n",
       " 'provavelmente',\n",
       " 'katia',\n",
       " 'valor',\n",
       " 'pt',\n",
       " 'partido',\n",
       " 'deveria',\n",
       " 'te',\n",
       " 'la',\n",
       " 'absorvido',\n",
       " 'ao',\n",
       " 'parece',\n",
       " 'pt',\n",
       " 'gostava',\n",
       " 'katia',\n",
       " 'somente',\n",
       " 'ficasse',\n",
       " 'entrincheirada',\n",
       " 'dentro',\n",
       " 'pmdb',\n",
       " 'ou',\n",
       " 'seja',\n",
       " 'rebaixar',\n",
       " 'demais',\n",
       " 'resta',\n",
       " 'katia',\n",
       " 'ficar',\n",
       " 'chorando',\n",
       " 'pitangas',\n",
       " 'todos',\n",
       " 'cantos',\n",
       " 'em',\n",
       " 'tempo',\n",
       " 'momento',\n",
       " 'pt',\n",
       " 'cadastrou',\n",
       " 'katia',\n",
       " 'abreu',\n",
       " 'fileiras',\n",
       " 'que',\n",
       " 'situacao',\n",
       " 'patetica',\n",
       " 'ex',\n",
       " 'ministra',\n",
       " 'agricultura',\n",
       " 'dilma']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield (gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "\n",
    "all_documents = list(df_filtered[\"text\"].copy())\n",
    "data_words = list(sent_to_words(all_documents))\n",
    "data_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lemmatization\n",
    "\n",
    "Lemmatization is a process where we convert words to its root word.\n",
    "\n",
    "For example: ‘Studying’ becomes ‘Study’, ‘Meeting becomes ‘Meet’, ‘Better’ and ‘Best’ becomes ‘Good’.\n",
    "\n",
    "The advantage of this is, we get to reduce the total number of unique words in the dictionary. As a result, the number of columns in the document-word matrix (created by CountVectorizer in the next step) will be denser with lesser columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you're unable to run the cell below, make sure you have pt_core_news_sm from spacy.\n",
    "\n",
    "### To download it, run `python -m spacy download pt_core_news_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'katia abreu dizer colocar expulsao moldurar reclamar abreu partir dizer expulsao pmdb resultar cupula atual legendar oportunista amanhar botar moldurar dourar expulsao maos vir atestar bom conduta curriculo pessoa expulsar servir pai servir pai beneficios proprios dizer katia abreu expulsao bom curriculo tanto choradeira katia saber motivar provavelmente katia valor pt partir dever absorver parecer gostar katia somente ficar entrincheirar dentro pmdb rebaixar demais restar katia ficar chorar pitanga canto momento cadastrar abreu fileira situacao patetica ministro agricultura'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append(\n",
    "            \" \".join(\n",
    "                [\n",
    "                    token.lemma_ if token.lemma_ not in [\"-PRON-\"] else \"\"\n",
    "                    for token in doc\n",
    "                    if token.pos_ in allowed_postags\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "# Initialize spacy 'pt_core_news_sm' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download pt_core_news_sm\n",
    "nlp = spacy.load(\"pt_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(\n",
    "    data_words, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    ")\n",
    "data_lemmatized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('katia abreu colocar expulsao moldurar reclamar abreu expulsao pmdb resultar cupula atual legendar oportunista amanhar botar moldurar dourar expulsao maos vir atestar conduta curriculo pessoa expulsar servir pai servir pai beneficios proprios katia abreu expulsao curriculo choradeira katia motivar provavelmente katia pt dever absorver parecer gostar katia ficar entrincheirar pmdb rebaixar restar katia ficar chorar pitanga canto cadastrar abreu fileira situacao patetica ministro agricultura',\n",
       " 'senado aprovar turno foro privilegiar politicos autoridade proposto foro caso autoridade cometer crime comum roubar corrupcao texto preciso passar votacao senado antar camara senado aprovar feirar turno proposto emendar constituicao pec acabar prerrogativa foro autoridade caso praticar crime comum roubar corrupcao pec aprovar voto votar contrariar tratar alteracao texto constitucional proposto preciso passar segundar turno votacao senado antar seguir camara deputar precisar analisar votacoes lei vigorar atualmente politicos senador deputar federar ministro direito investigar julgar esfera federal casar governador foro superior tribunal stj prefeito julgar tribunal justica proposto aprovar autoridade deverao julgar instancia eventual crime ocorrer tribunal superior projeto estabelecer excecao presidente republicar camara senado federal texto autoria senador alvaro pv atingir pessoa relator redar ap atualmente possuir prerrogativa foro pai politicos detentor mandato ministro juizes procurador desembargador autoridade atualmente julgar tribunal especializar relatorio aprovar turno randolfe acolher emendar sugestao alteracao senador ricardo ferraco psdb foro privilegiar presidente tres apresentar emendar ferraco argumentar deixar presidente republicar camara senado texto provocar pulverizacao acoes autoridade casar proposto vigor deputar senador perderao prerrogativa foro passarao julgar instancia judiciario relator proposto explicar lei politicar contar foro privilegiar processar remeter instancias inferior regrar valer casar projeto virar politicos investigar lavar jato cair foro privilegiar processar cair juiz promotor instancia foro responder processar recair instancia judicial respectivo juiz federal instancia declarar randolfe acusacao ambito operacao lavar jato varar federal varar investigacao valer processo andamento completar senador amapa proposto acabar prerrogativa foro caso crime previsto ministro presidente republicar ministro stf caso caber congresso nacional processar autoridade prever constituicao federal relator proposto votacao obstrucao expressivo senado relacionar possibilidade julgar proposto estabelecer limite foro privilegiar proximo mes')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = set(stopwordsiso.stopwords(\"pt\"))\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    # print(text)\n",
    "    return \" \".join([t for t in text.split(\" \") if t not in stops])\n",
    "\n",
    "\n",
    "data_no_stopwords = [remove_stopwords(text) for text in data_lemmatized]\n",
    "data_no_stopwords[0], data_no_stopwords[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Update DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>errors</th>\n",
       "      <th>pausatility</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words in upper case</th>\n",
       "      <th>average sentence length</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>katia abreu colocar expulsao moldurar reclamar...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.23080</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2017-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>10.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>ray peitar bolsonaro chamar conservador entrev...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.14290</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>100.txt</td>\n",
       "      <td>afolhabrasil.com.br</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>desmascarar policiar federal ferrenho criticar...</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.18750</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>1000.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>relatorio assustador mostrar dinheiro publicar...</td>\n",
       "      <td>639.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.88000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2017-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>1001.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>radialista americano falir vender ilusao brasi...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.84211</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>true</td>\n",
       "      <td>975.txt</td>\n",
       "      <td>g1.globo.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.316493</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>2.670210</td>\n",
       "      <td>gracas internet facilitar odiar karnal histori...</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.51060</td>\n",
       "      <td>405.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>true</td>\n",
       "      <td>983.txt</td>\n",
       "      <td>g1.globo.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.281106</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>2.963300</td>\n",
       "      <td>mpf querer ouvir dilma mantega contar joesley ...</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.40370</td>\n",
       "      <td>324.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>true</td>\n",
       "      <td>984.txt</td>\n",
       "      <td>g1.globo.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.253707</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>3.014080</td>\n",
       "      <td>temer falir reducao desmatamento amazonia refo...</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.26760</td>\n",
       "      <td>391.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2017-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>true</td>\n",
       "      <td>987.txt</td>\n",
       "      <td>g1.globo.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.208092</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>2.951220</td>\n",
       "      <td>cortar verba pf afeta lavar jato afirmar coord...</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.95120</td>\n",
       "      <td>435.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2017-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>true</td>\n",
       "      <td>992.txt</td>\n",
       "      <td>g1.globo.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.183824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.370370</td>\n",
       "      <td>senado aprovar turno foro privilegiar politico...</td>\n",
       "      <td>666.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.29630</td>\n",
       "      <td>187.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2017-04-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1718 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      file                   link  category  emotiveness    errors  \\\n",
       "0     fake     1.txt  ceticismopolitico.com  politica     0.263158  0.000000   \n",
       "1     fake    10.txt  ceticismopolitico.com  politica     0.241667  0.007874   \n",
       "2     fake   100.txt    afolhabrasil.com.br  politica     0.127820  0.003636   \n",
       "3     fake  1000.txt     diariodobrasil.org  politica     0.229008  0.001748   \n",
       "4     fake  1001.txt     diariodobrasil.org  politica     0.269231  0.000000   \n",
       "...    ...       ...                    ...       ...          ...       ...   \n",
       "7173  true   975.txt           g1.globo.com  politica     0.316493  0.001933   \n",
       "7182  true   983.txt           g1.globo.com  politica     0.281106  0.005096   \n",
       "7183  true   984.txt           g1.globo.com  politica     0.253707  0.001462   \n",
       "7186  true   987.txt           g1.globo.com  politica     0.208092  0.001287   \n",
       "7192  true   992.txt           g1.globo.com  politica     0.183824  0.000000   \n",
       "\n",
       "      pausatility                                               text  tokens  \\\n",
       "0        2.000000  katia abreu colocar expulsao moldurar reclamar...   211.0   \n",
       "1        2.500000  ray peitar bolsonaro chamar conservador entrev...   289.0   \n",
       "2        1.812500  desmascarar policiar federal ferrenho criticar...   304.0   \n",
       "3        2.680000  relatorio assustador mostrar dinheiro publicar...   639.0   \n",
       "4        0.894737  radialista americano falir vender ilusao brasi...   128.0   \n",
       "...           ...                                                ...     ...   \n",
       "7173     2.670210  gracas internet facilitar odiar karnal histori...  1803.0   \n",
       "7182     2.963300  mpf querer ouvir dilma mantega contar joesley ...  1893.0   \n",
       "7183     3.014080  temer falir reducao desmatamento amazonia refo...  1582.0   \n",
       "7186     2.951220  cortar verba pf afeta lavar jato afirmar coord...  1796.0   \n",
       "7192     3.370370  senado aprovar turno foro privilegiar politico...   666.0   \n",
       "\n",
       "      words in upper case  average sentence length  nouns  verbs  adverbs  \\\n",
       "0                     6.0                 14.23080   46.0   30.0     13.0   \n",
       "1                     0.0                 18.14290   64.0   56.0     18.0   \n",
       "2                     0.0                 17.18750   88.0   45.0      8.0   \n",
       "3                    14.0                 22.88000  175.0   87.0     21.0   \n",
       "4                     1.0                  5.84211   31.0   21.0      8.0   \n",
       "...                   ...                      ...    ...    ...      ...   \n",
       "7173                 11.0                 16.51060  405.0  268.0     99.0   \n",
       "7182                  9.0                 14.40370  324.0  327.0    145.0   \n",
       "7183                 13.0                 19.26760  391.0  216.0     55.0   \n",
       "7186                 29.0                 18.95120  435.0  257.0     79.0   \n",
       "7192                 11.0                 21.29630  187.0   85.0     19.0   \n",
       "\n",
       "      adjectives  pronouns        date  \n",
       "0            7.0      26.0  2017-11-30  \n",
       "1           11.0      20.0  2017-11-24  \n",
       "2            9.0      18.0  2017-05-23  \n",
       "3           39.0      34.0  2017-07-24  \n",
       "4            6.0      12.0  2017-07-25  \n",
       "...          ...       ...         ...  \n",
       "7173       114.0     147.0  2017-01-27  \n",
       "7182        38.0     187.0  2017-06-30  \n",
       "7183        99.0      73.0  2017-09-19  \n",
       "7186        65.0      70.0  2017-07-28  \n",
       "7192        31.0      22.0  2017-04-26  \n",
       "\n",
       "[1718 rows x 17 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "for i in range(len(df_filtered)):\n",
    "    df_filtered.iloc[i, df.columns.get_loc(\"text\")] = data_no_stopwords[i]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"./processed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fc39119fb53716d71d336af58d9742de59e9604ecf17036cb692bed5894ed0e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
