{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cufflinks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bb7f1bb5be19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcufflinks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgo_offline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_config_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_readable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cufflinks'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "from textblob import TextBlob\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "  vec = CountVectorizer().fit(corpus)\n",
    "  bag_of_words = vec.transform(corpus)\n",
    "  sum_words = bag_of_words.sum(axis=0) \n",
    "  words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "  words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "  return words_freq[:n]\n",
    "\n",
    "def get_top_n_bigram(corpus, n=None):\n",
    "  vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "  bag_of_words = vec.transform(corpus)\n",
    "  sum_words = bag_of_words.sum(axis=0) \n",
    "  words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "  words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "  return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../pre-processed.csv')\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "df.sample(20).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    only_ascii = unidecode.unidecode(input_str)\n",
    "    return only_ascii\n",
    "\n",
    "stops = list(set(stopwords.words('portuguese')))\n",
    "for i in range(0, len(stops)):\n",
    "  stops[i] = remove_accents(stops[i])\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  words = text.split()\n",
    "  words = [word for word in words if word not in stops]\n",
    "  return ' '.join(words)\n",
    "\n",
    "df['preprocessed_news'] = df['preprocessed_news'].apply(remove_stopwords)\n",
    "df['review_length'] = df['preprocessed_news'].apply(lambda x: len(str(x)))\n",
    "df['word_count'] = df['preprocessed_news'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'] = df['preprocessed_news'].map(lambda text: TextBlob(text).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'].iplot(\n",
    "  kind='hist',\n",
    "  bins=50,\n",
    "  xTitle='polarity',\n",
    "  linecolor='black',\n",
    "  yTitle='count',\n",
    "  title='Sentiment Polarity Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_length'].iplot(\n",
    "  kind='hist',\n",
    "  bins=100,\n",
    "  xTitle='review length',\n",
    "  linecolor='black',\n",
    "  yTitle='count',\n",
    "  title='Review Text Length Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'].iplot(\n",
    "  kind='hist',\n",
    "  bins=100,\n",
    "  xTitle='word count',\n",
    "  linecolor='black',\n",
    "  yTitle='count',\n",
    "  title='Review Text Word Count Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df.loc[df['label'] == 'fake']['preprocessed_news']\n",
    "allwords = []\n",
    "for wordlist in words:\n",
    "  allwords += wordlist.split()\n",
    "\n",
    "mostcommon = FreqDist(allwords).most_common(100)\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Words in Fake News', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_fake = get_top_n_words(df.loc[df['label'] == 'fake']['preprocessed_news'], 20)\n",
    "dfcf = pd.DataFrame(common_words_fake, columns = ['preprocessed_news' , 'count'])\n",
    "dfcf.groupby('preprocessed_news').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    title='Top 20 words in fake news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_bigrams_fake = get_top_n_bigram(df.loc[df['label'] == 'fake']['preprocessed_news'], 20)\n",
    "dfbf = pd.DataFrame(common_bigrams_fake, columns = ['preprocessed_news' , 'count'])\n",
    "dfbf.groupby('preprocessed_news').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    title='Top 20 bigrams in fake news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_true = df.loc[df['label'] == 'true']['preprocessed_news']\n",
    "allwords_true = []\n",
    "for wordlist_true in words_true:\n",
    "  allwords_true += wordlist_true.split()\n",
    "\n",
    "mostcommon_true = FreqDist(allwords_true).most_common(100)\n",
    "\n",
    "wordcloud_true = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon_true))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud_true, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Words in True News', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_top_n_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4cd110b33e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcommon_words_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'true'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessed_news'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon_words_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessed_news'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m dfct.groupby('preprocessed_news').sum()['count'].sort_values(ascending=False).iplot(\n\u001b[0;32m      4\u001b[0m     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0myTitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_top_n_words' is not defined"
     ]
    }
   ],
   "source": [
    "common_words_true = get_top_n_words(df.loc[df['label'] == 'true']['preprocessed_news'], 20)\n",
    "dfct = pd.DataFrame(common_words_true, columns = ['preprocessed_news' , 'count'])\n",
    "dfct.groupby('preprocessed_news').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    title='Top 20 words in true news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_top_n_bigram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f0aa55cd3a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcommon_bigrams_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_n_bigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'true'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessed_news'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfbt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon_bigrams_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessed_news'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m dfbt.groupby('preprocessed_news').sum()['count'].sort_values(ascending=False).iplot(\n\u001b[0;32m      4\u001b[0m     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0myTitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_top_n_bigram' is not defined"
     ]
    }
   ],
   "source": [
    "common_bigrams_true = get_top_n_bigram(df.loc[df['label'] == 'true']['preprocessed_news'], 20)\n",
    "dfbt = pd.DataFrame(common_bigrams_true, columns = ['preprocessed_news' , 'count'])\n",
    "dfbt.groupby('preprocessed_news').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    title='Top 20 bigrams in true news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6370919930b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessed_news'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpos_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'pos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpos_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m pos_df.iplot(\n\u001b[0;32m      5\u001b[0m   \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "blob = TextBlob(str(df['preprocessed_news']))\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df = pos_df.pos.value_counts()[:20]\n",
    "pos_df.iplot(\n",
    "  kind='bar',\n",
    "  xTitle='POS',\n",
    "  yTitle='count', \n",
    "  title='Top 20 Part-of-speech tagging for news corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
