{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05b9ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba571e7a",
   "metadata": {},
   "source": [
    "## META-INFORMATION FILES info e seu número correspondente\n",
    "\n",
    "0.  author\n",
    "1.  link\n",
    "2.  category\n",
    "3.  date of publication\n",
    "4.  number of tokens\n",
    "5.  number of words without punctuation\n",
    "6.  number of types\n",
    "7.  number of links inside the news\n",
    "8.  number of words in upper case\n",
    "9.  number of verbs\n",
    "10. number of subjuntive and imperative verbs\n",
    "11. number of nouns\n",
    "12. number of adjectives\n",
    "13. number of adverbs\n",
    "14. number of modal verbs (mainly auxiliary verbs)\n",
    "15. number of singular first and second personal pronouns\n",
    "16. number of plural first personal pronouns\n",
    "17. number of pronouns\n",
    "18. pausality\n",
    "19. number of characters\n",
    "20. average sentence length\n",
    "21. average word length\n",
    "22. percentage of news with speeling errors\n",
    "23. emotiveness\n",
    "24. diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e67c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_info = os.listdir(\"full_texts/fake-meta-information\")\n",
    "true_info = os.listdir(\"full_texts/true-meta-information\")\n",
    "\n",
    "i = 0\n",
    "label = \"fake\"\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# para cada pasta\n",
    "for files in [fake_info, true_info]:\n",
    "    # le cada um dos arquivos\n",
    "    for file in files:\n",
    "        with open(\n",
    "            \"full_texts/\" + label + \"-meta-information/\" + file, \"r\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            # text = f.read() # texto como única string\n",
    "            # text = f.readline() # le linha por linha\n",
    "            text = f.readlines()  # le todas as linhas e bota numa lista\n",
    "            f.close()\n",
    "        # trocar \"full_texts\" por \"size_normalized_texts\" se ja quiser trabalhar com os textos normalizados\n",
    "        file = file.split(\"-\")[0] + \".txt\"\n",
    "        with open(\"full_texts/\" + label + \"/\" + file, \"r\", encoding=\"utf-8\") as f2:\n",
    "            text2 = f2.read()\n",
    "            f2.close()\n",
    "\n",
    "        # salva essas informações\n",
    "        df.loc[i, \"label\"] = label\n",
    "        df.loc[i, \"file\"] = file\n",
    "        df.loc[i, \"link\"] = urlparse(text[1].replace(\"\\n\", \"\")).netloc.replace(\n",
    "            \"www.\", \"\"\n",
    "        )\n",
    "        df.loc[i, \"category\"] = text[2].replace(\"\\n\", \"\")\n",
    "        df.loc[i, \"emotiveness\"] = float(text[23].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"errors\"] = float(text[22].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"pausatility\"] = float(text[18].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"text\"] = text2\n",
    "        df.loc[i, \"tokens\"] = float(text[4].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"words in upper case\"] = float(text[8].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"average sentence length\"] = float(text[20].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"nouns\"] = float(text[11].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"verbs\"] = float(text[9].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"adverbs\"] = float(text[13].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"adjectives\"] = float(text[12].replace(\"\\n\", \"\"))\n",
    "        df.loc[i, \"pronouns\"] = float(text[17].replace(\"\\n\", \"\"))\n",
    "\n",
    "        # hate the bad formating not the player\n",
    "        try:\n",
    "            # formatação padrao ingles\n",
    "            df.loc[i, \"date\"] = datetime.strptime(\n",
    "                text[3].replace(\"\\n\", \"\").split(\" \")[0], \"%Y-%m-%d\"\n",
    "            ).date()\n",
    "        except:\n",
    "            try:\n",
    "                # esse segue a formatação brasileira\n",
    "                df.loc[i, \"date\"] = datetime.strptime(\n",
    "                    text[3].replace(\"\\n\", \"\").split(\" \")[0], \"%d/%m/%Y\"\n",
    "                ).date()\n",
    "            except:\n",
    "                try:\n",
    "                    # esse é pq tem data com um espaço antes da data, ai o split da ruim\n",
    "                    # o slipt[0] é necessário pq tem data solo e data com algum formato de hora logo após\n",
    "                    df.loc[i, \"date\"] = datetime.strptime(\n",
    "                        text[3].replace(\"\\n\", \"\").split(\" \")[1], \"%d/%m/%Y\"\n",
    "                    ).date()\n",
    "                except:\n",
    "                    # esse foi pq cansei, algum arquivo deu q '16' não é um date pra converter, teria que ver a formatação desse arquivo\n",
    "                    df.loc[i, \"date\"] = np.nan\n",
    "        i += 1\n",
    "    label = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ab06cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>errors</th>\n",
       "      <th>pausatility</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words in upper case</th>\n",
       "      <th>average sentence length</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Kátia Abreu diz que vai colocar sua expulsão e...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.23080</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2017-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>10.txt</td>\n",
       "      <td>ceticismopolitico.com</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>Dr. Ray peita Bolsonaro, chama-o de conservad...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.14290</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>100.txt</td>\n",
       "      <td>afolhabrasil.com.br</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>Reinaldo Azevedo desmascarado pela Polícia Fed...</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.18750</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>1000.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>Relatório assustador do BNDES mostra dinheiro ...</td>\n",
       "      <td>639.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.88000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2017-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>1001.txt</td>\n",
       "      <td>diariodobrasil.org</td>\n",
       "      <td>politica</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>Radialista americano fala sobre o PT: \"Eles ve...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.84211</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      file                   link  category  emotiveness    errors  \\\n",
       "0  fake     1.txt  ceticismopolitico.com  politica     0.263158  0.000000   \n",
       "1  fake    10.txt  ceticismopolitico.com  politica     0.241667  0.007874   \n",
       "2  fake   100.txt    afolhabrasil.com.br  politica     0.127820  0.003636   \n",
       "3  fake  1000.txt     diariodobrasil.org  politica     0.229008  0.001748   \n",
       "4  fake  1001.txt     diariodobrasil.org  politica     0.269231  0.000000   \n",
       "\n",
       "   pausatility                                               text  tokens  \\\n",
       "0     2.000000  Kátia Abreu diz que vai colocar sua expulsão e...   211.0   \n",
       "1     2.500000  Dr. Ray peita Bolsonaro, chama-o de conservad...   289.0   \n",
       "2     1.812500  Reinaldo Azevedo desmascarado pela Polícia Fed...   304.0   \n",
       "3     2.680000  Relatório assustador do BNDES mostra dinheiro ...   639.0   \n",
       "4     0.894737  Radialista americano fala sobre o PT: \"Eles ve...   128.0   \n",
       "\n",
       "   words in upper case  average sentence length  nouns  verbs  adverbs  \\\n",
       "0                  6.0                 14.23080   46.0   30.0     13.0   \n",
       "1                  0.0                 18.14290   64.0   56.0     18.0   \n",
       "2                  0.0                 17.18750   88.0   45.0      8.0   \n",
       "3                 14.0                 22.88000  175.0   87.0     21.0   \n",
       "4                  1.0                  5.84211   31.0   21.0      8.0   \n",
       "\n",
       "   adjectives  pronouns        date  \n",
       "0         7.0      26.0  2017-11-30  \n",
       "1        11.0      20.0  2017-11-24  \n",
       "2         9.0      18.0  2017-05-23  \n",
       "3        39.0      34.0  2017-07-24  \n",
       "4         6.0      12.0  2017-07-25  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f2cbab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Ray peita Bolsonaro, chama-o de conservador fake em entrevista a Danilo Gentili e divide a direita.\n",
      "\n",
      "Este site vem avisando Jair Bolsonaro que ele deveria abandonar a pauta estatista de vez e fazer um discurso mais convincente para aquela boa parte dos liberais e conservadores do Brasil que querem se ver livres das amarras estatais.\n",
      "\n",
      "Tudo bem que as pesquisas ainda dizem que a maior parte do povo é contra as privatizações, mas o índice (pouco mais de 50% do povo) é fácil de ser revertido. Ademais, Bolsonaro deveria falar para direitistas em vez de focar tanto em petistas arrependidos.\n",
      "\n",
      "Recentemente ele disse que pensaria 200 vezes antes de privatizar a Petrobrás para que ela não caia nas mãos de chineses (ou algo do tipo). Deveria ter dito: Eu garanto a privatização da Petrobrás, e também garanto que chineses não irão comprá-la. Isso não deixaria brechas. Do jeito que ele falou, parece que o suposto medo de venda aos chineses é pretexto para evitar a privatização.\n",
      "\n",
      "Seja lá como for, a direita vai ter que adotar alternativas que foquem em um estado reduzido, diminuição de impostos e venda de estatais. Além de João Amoedo, Dr. Rey está fazendo vicejar este tipo de discurso e  ainda que sua candidatura esteja em fase inicial  é complicado para Bolsonaro que apareçam pessoas de direita propondo uma visão economicamente direitista para a economia.\n",
      "\n",
      "Enfim, veja aos 32:40 Dr. Rey espinafrando Bolsonaro: Quem dá brechas não pode reclamar que os outros aproveitem, não é mesmo?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[1, \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f6927",
   "metadata": {},
   "source": [
    "## Tratamento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5ab9f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unidecode\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5819d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover acentos e stopwords\n",
    "def remove_accents(input_str):\n",
    "    only_ascii = unidecode.unidecode(input_str)\n",
    "    return only_ascii\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stops]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48867317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-1920b0cd2e29>:8: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops = list(set(stopwords.words(\"portuguese\")))\n",
    "for i in range(0, len(stops)):\n",
    "    stops[i] = remove_accents(stops[i])\n",
    "\n",
    "df[\"text\"] = (\n",
    "    df[\"text\"]\n",
    "    .str.normalize(\"NFKD\")\n",
    "    .str.encode(\"ascii\", errors=\"ignore\")\n",
    "    .str.decode(\"utf-8\")\n",
    ")\n",
    "df[\"text\"] = df[\"text\"].apply(remove_stopwords)\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"/[^\\x00-\\x7F]/g\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77c3ac4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr. ray peita bolsonaro, chama-o conservador fake entrevista danilo gentili divide direita. este site vem avisando jair bolsonaro deveria abandonar pauta estatista vez fazer discurso convincente boa parte liberais conservadores brasil querem ver livres amarras estatais. tudo bem pesquisas ainda dizem maior parte povo contra privatizacoes, indice (pouco 50% povo) facil ser revertido. ademais, bolsonaro deveria falar direitistas vez focar tanto petistas arrependidos. recentemente disse pensaria 200 vezes antes privatizar petrobras caia maos chineses (ou algo tipo). deveria ter dito: eu garanto privatizacao petrobras, garanto chineses irao compra-la. isso deixaria brechas. do jeito falou, parece suposto medo venda chineses pretexto evitar privatizacao. seja la for, direita vai ter adotar alternativas foquem estado reduzido, diminuicao impostos venda estatais. alem joao amoedo, dr. rey fazendo vicejar tipo discurso ainda candidatura fase inicial complicado bolsonaro aparecam pessoas direita propondo visao economicamente direitista economia. enfim, veja 32:40 dr. rey espinafrando bolsonaro: quem brechas pode reclamar outros aproveitem, mesmo?\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[1, \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "303f3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"all_together.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5af3b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b38399",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd044d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd6d93",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6bc2c",
   "metadata": {},
   "source": [
    "##### ATENÇÃO ###\n",
    " Os index do arquivo pre-processed não batem com o nome dos arquivos da pasta full_text, \n",
    " tanto o arquivo cru quanto o meta-information, porém, o index pelo df batem, isso provavelmente pq usaram python tmb\n",
    " e o python ordenou 1, 10, 1000, 1001, 1002, ... como os primeiros, por se tratar de string e não número, \n",
    " ai o index fico zuado e eles não trocaram pelo verdadeiro número do arquivo\n",
    "\n",
    " Realizar essa consideração quando utilizar o csv do pre-processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
