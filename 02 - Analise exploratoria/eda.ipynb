{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "from textblob import TextBlob\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "from nltk import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>true</td>\n",
       "      <td>presidente afastada dilma rousseff tentou cond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6978</th>\n",
       "      <td>true</td>\n",
       "      <td>cuba comemorara primeiro aniversario morte emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>fake</td>\n",
       "      <td>passagem bahamas furacao irma tao poderoso sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>true</td>\n",
       "      <td>moro ouve youssef cervero baiano acao contra l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>fake</td>\n",
       "      <td>ator petista podera interpretar tucano aecio n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                  preprocessed_news\n",
       "5542  true  presidente afastada dilma rousseff tentou cond...\n",
       "6978  true  cuba comemorara primeiro aniversario morte emb...\n",
       "3376  fake  passagem bahamas furacao irma tao poderoso sug...\n",
       "6194  true  moro ouve youssef cervero baiano acao contra l...\n",
       "2159  fake  ator petista podera interpretar tucano aecio n..."
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../pre-processed.csv')\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "df.sample(20).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    only_ascii = unidecode.unidecode(input_str)\n",
    "    return only_ascii\n",
    "\n",
    "stops = list(set(stopwords.words('portuguese')))\n",
    "for i in range(0, len(stops)):\n",
    "  stops[i] = remove_accents(stops[i])\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  words = text.split()\n",
    "  words = [word for word in words if word not in stops]\n",
    "  return ' '.join(words)\n",
    "\n",
    "df['preprocessed_news'] = df['preprocessed_news'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'] = df['preprocessed_news'].map(lambda text: TextBlob(text).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'].iplot(\n",
    "  kind='hist',\n",
    "  bins=50,\n",
    "  xTitle='polarity',\n",
    "  linecolor='black',\n",
    "  yTitle='count',\n",
    "  title='Sentiment Polarity Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df.loc[df['label'] == 'fake']['preprocessed_news']\n",
    "allwords = []\n",
    "for wordlist in words:\n",
    "  allwords += wordlist.split()\n",
    "\n",
    "mostcommon = FreqDist(allwords).most_common(100)\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Words in Fake News', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_true = df.loc[df['label'] == 'true']['preprocessed_news']\n",
    "allwords_true = []\n",
    "for wordlist_true in words_true:\n",
    "  allwords_true += wordlist_true.split()\n",
    "\n",
    "mostcommon_true = FreqDist(allwords_true).most_common(100)\n",
    "\n",
    "wordcloud_true = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon_true))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud_true, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Words in True News', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
